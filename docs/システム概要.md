## ざっくり
音声入力で得られたテキストをAI(Gemini)に投げて、その応答をVoiceBoxに読み上げさせる。
流れとしては、
1. 音声入力: 音声 → テキスト
2. Gemini: テキスト → テキスト
3. VoiceBox: テキスト → 音声

このように音声同士での会話が実現されている。

## 音声入力
音声入力はブラウザが提供するWeb Speech APIを利用している。
まず、マイクボタンを押すと背景が緑色から赤色に変わり、音声認識が始まる。
この間はどれだけ間をおいても、声を拾ってくれる。

もう一度ボタンを押すと背景が緑色に戻り、音声認識が止まる。
この時点で内容は確定しているので、雑音を拾う心配はない

入力内容が正しく声を拾えていなかったり誤変換が目立つ場合は、もう一度音声認識を開始してやり直すことも出来る。
あと音声認識中でも送信ボタンを押せばその時点で認識が止まる。

## Gemini: テキスト処理
GeminiはGoogleが提供する生成AIであり、一般にLLMと呼ばれる。
先の音声入力によって得られたユーザーのテキストをGeminiに投げて、応答メッセージをもらう。

このGeminiではあらかじめ回答の形式について指示（プロンプト）を出せる。
これが上手くいけば私たちが期待する応答メッセージを得られる。

タコトークでは本家のような面白さを目指しつつ独自の個性を持たせたかったため、このプロンプトの調整に苦戦した。

## VoiceBox: 合成音声
合成音声にはVoiceBoxを使っている。
これを経由することによってテキストを音声出力することが出来る。
現在は第3者が公開している非公式のAPIを利用している。

参考：[WEB版VOICEVOX API（高速）](https://voicevox.su-shiki.com/su-shikiapis/)
